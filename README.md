# Speech-to-Text-System2
*COMPANY*: COOTECH IT SOLUTIONS
*NAME*: MAYANK GUSAIN
*INTERN ID*: CITS0D838
*DOMAIN*: ARTIFICIAL INTELLIGENCE
*DURATION*: 4 WEEEKS
*MENTOR*: NEELA SANTOSH KUMAR

*DESCRIPTION*: For Task 2 of my CodTech AI internship, I developed a Speech-to-Text System designed to automatically convert spoken audio into written text using pre-trained models and open-source Python libraries. The main objective of this task is to demonstrate how artificial intelligence can interpret and transcribe human speech, which is a fundamental feature in modern voice assistants, transcription services, and many AI-driven applications.

To implement this task, I used Python as the primary programming language and carried out the development and testing process on Google Colab, a cloud-based notebook platform. Google Colab is ideal for machine learning and AI projects because it provides a free, ready-to-use environment with pre-installed libraries and access to powerful computation resources. This means I could run my speech recognition code easily without worrying about setting up packages on my local system.

For the speech-to-text conversion, I used the popular SpeechRecognition Python library. This library offers a simple interface to various speech recognition engines and APIs. For this task, I used Google’s free Web Speech API through SpeechRecognition because it is accurate, easy to set up, and suitable for short audio clips.

The implementation process was straightforward yet insightful. First, I installed the SpeechRecognition library inside my Google Colab notebook. I then used the Colab file upload feature to upload a sample audio file. For testing, I recorded a short .wav file that says, “Hey, this is a sample test for speech recognition.” In some cases, if the audio is in .mp3 format, I used the pydub library to convert it to .wav since the recognizer works more reliably with .wav files.
Next, I initialized the recognizer and loaded the audio file using sr.AudioFile. I then read the audio data and passed it to Google’s recognizer through recognizer.recognize_google(). The result is a clean, accurate text version of the spoken words. To ensure this output could be verified, I printed the transcribed text directly in the notebook’s output cell and also saved it to a text file named transcription_output.txt. In Google Colab, I generated a download link for this file so it could be downloaded and checked outside the notebook.

To demonstrate proof of successful execution, I took a clear screenshot of my Colab notebook showing the code, the transcribed text output, and the file download step. This screenshot has been added to my GitHub repository as screenshot_task2.png and linked in the README.md for easy reference.

Through this task, I learned how speech recognition works, how to handle audio data in Python, and how to integrate speech APIs in a real-world project. I also gained experience using Google Colab for practical AI development. Overall, this task highlights how AI can bridge the gap between human language and digital text, which is a core part of many AI-driven tools and voice-controlled applications today. By completing Task 2, I demonstrated my understanding of speech-to-text processing and my ability to implement and test it efficiently using cloud-based tools.

*OUTPUT*
[transcription_output.txt](https://github.com/user-attachments/files/20846721/transcription_output.txt)

![Image](https://github.com/user-attachments/assets/d785d8ae-6a45-4d7c-ae60-12a295981494)

